{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T20:44:43.645685Z",
     "start_time": "2024-11-06T20:44:43.639485Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:44:45.941692Z",
     "start_time": "2024-11-06T20:44:44.557664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 1: Fetch Data from the API\n",
    "def fetch_data(start_date, end_date):\n",
    "    url = f\"https://api.energy-charts.info/price?bzn=DE-LU&start={start_date}&end={end_date}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extracting timestamps and prices, converting timestamps to datetime\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': pd.to_datetime(data['unix_seconds'], unit='s'),\n",
    "        'price': data['price']\n",
    "    })\n",
    "\n",
    "    # Dropping rows with null prices (if any)\n",
    "    df = df.dropna(subset=['price']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Define the date range for 1 year and 1 month\n",
    "start_date = '2022-01-01'  # Start date for 1 year of training\n",
    "end_date = '2023-02-01'  # End date, covering 1 year and 1 month\n",
    "\n",
    "# Fetch the data\n",
    "df = fetch_data(start_date, end_date)\n"
   ],
   "id": "3a56bc1f9ad46da7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:44:46.427647Z",
     "start_time": "2024-11-06T20:44:46.374599Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(100)",
   "id": "562c57b3866e6ce5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             timestamp   price\n",
       "0  2021-12-31 23:00:00   50.05\n",
       "1  2022-01-01 00:00:00   41.33\n",
       "2  2022-01-01 01:00:00   43.22\n",
       "3  2022-01-01 02:00:00   45.46\n",
       "4  2022-01-01 03:00:00   37.67\n",
       "..                 ...     ...\n",
       "95 2022-01-04 22:00:00   97.56\n",
       "96 2022-01-04 23:00:00  105.31\n",
       "97 2022-01-05 00:00:00   97.29\n",
       "98 2022-01-05 01:00:00   84.50\n",
       "99 2022-01-05 02:00:00   75.38\n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>50.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>41.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>43.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>45.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>37.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-01-04 22:00:00</td>\n",
       "      <td>97.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2022-01-04 23:00:00</td>\n",
       "      <td>105.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2022-01-05 00:00:00</td>\n",
       "      <td>97.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2022-01-05 01:00:00</td>\n",
       "      <td>84.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2022-01-05 02:00:00</td>\n",
       "      <td>75.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:45:45.842992Z",
     "start_time": "2024-11-06T20:45:45.834273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Ensure hourly frequency and add lagged feature\n",
    "df = df.set_index('timestamp').asfreq('H').reset_index()  # Fill in missing hours if any\n",
    "df['Price_lag_1d'] = df['price'].shift(24)  # Use 1-day lag (24 hours ago)\n",
    "df.dropna(inplace=True)  # Drop rows without lag data\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "# Use the first year for training and the next month for testing\n",
    "train_df = df[df['timestamp'] < '2023-01-01']  # Training set: 1 year of data\n",
    "test_df = df[df['timestamp'] >= '2023-01-01']  # Testing set: the following month\n",
    "\n",
    "test_df.head(100)"
   ],
   "id": "eef2ee25f91cfe8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sf/ksj8v1wn3636lv_3k99ms0l80000gn/T/ipykernel_90354/3994351895.py:3: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.set_index('timestamp').asfreq('H').reset_index()  # Fill in missing hours if any\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               timestamp  price  Price_lag_1d\n",
       "8737 2023-01-01 00:00:00  -1.07         -0.07\n",
       "8738 2023-01-01 01:00:00  -1.47         -0.03\n",
       "8739 2023-01-01 02:00:00  -5.08         -0.04\n",
       "8740 2023-01-01 03:00:00  -4.49         -0.03\n",
       "8741 2023-01-01 04:00:00  -5.40         -0.02\n",
       "...                  ...    ...           ...\n",
       "8832 2023-01-04 23:00:00   0.05         80.89\n",
       "8833 2023-01-05 00:00:00   0.07         70.67\n",
       "8834 2023-01-05 01:00:00   0.07         40.00\n",
       "8835 2023-01-05 02:00:00   0.12          8.68\n",
       "8836 2023-01-05 03:00:00   2.23          0.85\n",
       "\n",
       "[100 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>price</th>\n",
       "      <th>Price_lag_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8738</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8739</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8740</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8741</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832</th>\n",
       "      <td>2023-01-04 23:00:00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>80.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>2023-01-05 00:00:00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>70.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>2023-01-05 01:00:00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>2023-01-05 02:00:00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8836</th>\n",
       "      <td>2023-01-05 03:00:00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:49:29.094760Z",
     "start_time": "2024-11-06T20:49:29.092546Z"
    }
   },
   "cell_type": "code",
   "source": "from neuralforecast.models import LSTM, NHITS, RNN",
   "id": "1423a5b818794ac1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:53:01.253683Z",
     "start_time": "2024-11-06T20:49:33.728623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Step 4: Configure Models and Prepare Data for Training\n",
    "\n",
    "# Define forecasting horizon and input sequence length\n",
    "horizon = 24  # Forecasts the next 24 hours\n",
    "input_size = 2 * horizon\n",
    "\n",
    "# Ensure the training data has the required columns\n",
    "# Prepare data for NeuralForecast model, with required columns 'unique_id', 'ds', and 'y'\n",
    "train_df = train_df.rename(columns={'timestamp': 'ds', 'price': 'y'})\n",
    "train_df['unique_id'] = 'price_series'  # Assign a unique ID for the time series\n",
    "\n",
    "# Define the models with LSTM and NBEATS configurations as per your example\n",
    "models = [\n",
    "    LSTM(\n",
    "        h=horizon,                         # Forecast horizon\n",
    "        max_steps=500,                     # Number of steps to train\n",
    "        scaler_type='standard',            # Scaler for normalization\n",
    "        encoder_hidden_size=64,            # Hidden state size of the LSTM\n",
    "        decoder_hidden_size=64             # Hidden units in each layer of MLP decoder\n",
    "    ),\n",
    "    NBEATS(\n",
    "        h=horizon,                         # Forecast horizon\n",
    "        input_size=input_size,             # Length of input sequence\n",
    "        max_steps=100                      # Training steps\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize NeuralForecast with models list and frequency\n",
    "nf = NeuralForecast(models=models, freq='H')  # 'H' for hourly frequency\n",
    "\n",
    "# Fit the model on the prepared training DataFrame\n",
    "nf.fit(df=train_df[['unique_id', 'ds', 'y']])\n",
    "\n"
   ],
   "id": "9ce8d6805b81e3f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | MAE           | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 50.4 K | train\n",
      "4 | context_adapter | Linear        | 15.6 K | train\n",
      "5 | mlp_decoder     | MLP           | 769    | train\n",
      "----------------------------------------------------------\n",
      "66.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "66.8 K    Total params\n",
      "0.267     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=23, train_loss_step=0.439, train_loss_epoch=0.439]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 628.55it/s]\u001B[A\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=23, train_loss_step=0.372, train_loss_epoch=0.373]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 607.61it/s]\u001B[A\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s, v_num=23, train_loss_step=0.307, train_loss_epoch=0.305]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 754.10it/s]\u001B[A\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=23, train_loss_step=0.294, train_loss_epoch=0.295]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 678.03it/s]\u001B[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, v_num=23, train_loss_step=0.265, train_loss_epoch=0.264]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 680.23it/s]\u001B[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s, v_num=23, train_loss_step=0.265, train_loss_epoch=0.265]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s, v_num=23, train_loss_step=0.265, train_loss_epoch=0.265]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.5 M  | train\n",
      "-------------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "3.5 K     Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.120    Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 36.03it/s, v_num=24, train_loss_step=41.00, train_loss_epoch=41.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 987.13it/s]\u001B[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 29.78it/s, v_num=24, train_loss_step=41.00, train_loss_epoch=41.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 28.45it/s, v_num=24, train_loss_step=41.00, train_loss_epoch=41.00]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:53:39.466233Z",
     "start_time": "2024-11-06T20:53:39.463394Z"
    }
   },
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt",
   "id": "2aae4adeb1c90f9a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T20:55:30.341242Z",
     "start_time": "2024-11-06T20:55:30.097209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Prediction and Visualization\n",
    "\n",
    "# Prepare test data in the same format as training data\n",
    "test_df = test_df.rename(columns={'timestamp': 'ds', 'price': 'y'})\n",
    "test_df['unique_id'] = 'price_series'  # Unique ID for time series\n",
    "\n",
    "# Predict for the test period (the next month)\n",
    "Y_hat_df = nf.predict(df=test_df[['unique_id', 'ds', 'y']])\n",
    "\n",
    "# Assuming Y_hat_df contains predictions from LSTM and NBEATS models,\n",
    "# let's concatenate actual (Y_df) and forecast data (Y_hat_df)\n",
    "# and plot them\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate actual and forecast data\n",
    "# Ensure Y_df is structured with columns: 'ds' (dates), 'y' (actual values)\n",
    "plot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds')\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 7))\n",
    "plot_df[['y', 'LSTM', 'NBEATS']].plot(ax=ax, linewidth=2)  # Adjust labels if necessary\n",
    "\n",
    "ax.set_title('Electricity Price Forecast', fontsize=22)\n",
    "ax.set_ylabel('Electricity Price', fontsize=20)\n",
    "ax.set_xlabel('Date', fontsize=20)\n",
    "ax.legend(prop={'size': 15})\n",
    "ax.grid()\n",
    "plt.show()"
   ],
   "id": "a52c6bd9890987b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i744722/opt/anaconda3/envs/machine_learning_test/lib/python3.11/site-packages/utilsforecast/processing.py:384: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "/Users/i744722/opt/anaconda3/envs/machine_learning_test/lib/python3.11/site-packages/utilsforecast/processing.py:438: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.94it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i744722/opt/anaconda3/envs/machine_learning_test/lib/python3.11/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 19\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Concatenate actual and forecast data\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Ensure Y_df is structured with columns: 'ds' (dates), 'y' (actual values)\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m plot_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([Y_df, Y_hat_df])\u001B[38;5;241m.\u001B[39mset_index(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Plotting\u001B[39;00m\n\u001B[1;32m     22\u001B[0m fig, ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Y_df' is not defined"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
